// reply_bot.ts
import { Agent, Runner, hostedMcpTool, withTrace } from "@openai/agents";

console.log("âœ… Reply bot starting...");

// ---- MCP å·¥å…·ï¼ˆHosted MCPï¼‰ ----
// å…³é”®ç‚¹ï¼šrequireApproval è®¾ä¸º "never"ï¼Œé¿å…å¡åœ¨äººå·¥æ‰¹å‡†ã€‚
const mcp = hostedMcpTool({
  serverLabel: "openisle_mcp",
  serverUrl: "https://www.open-isle.com/mcp",
  allowedTools: [
    "search",
    "reply_to_post",
    "reply_to_comment",
    "recent_posts",
    "get_post",
    "list_unread_messages"
  ],
  requireApproval: "never",
});

type WorkflowInput = { input_as_text: string };

// ä»ç¯å¢ƒå˜é‡è¯»å–ä½ çš„ç«™ç‚¹é‰´æƒä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
const OPENISLE_TOKEN = process.env.OPENISLE_TOKEN ?? "";

// ---- å®šä¹‰ Agent ----
const openisleBot = new Agent({
  name: "OpenIsle Bot",
  instructions: [
    "You are a helpful assistant for https://www.open-isle.com.",
    "Finish tasks end-to-end before replying. If multiple MCP tools are needed, call them sequentially until the task is truly done.",
    "When showing the result, reply in Chinese with a concise summary and include any important URLs or IDs.",
    OPENISLE_TOKEN
      ? `If tools require auth, use this token exactly where the tool schema expects it: ${OPENISLE_TOKEN}`
      : "If a tool requires auth, ask me to provide OPENISLE_TOKEN via env.",
  ].join("\n"),
  tools: [mcp],
  model: "gpt-4o",
  modelSettings: {
    temperature: 0.7,
    topP: 1,
    maxTokens: 2048,
    toolChoice: "auto",
    store: true,
  },
});

// ---- å…¥å£å‡½æ•°ï¼šè·‘åˆ°æ‹¿åˆ° finalOutput ä¸ºæ­¢ï¼Œç„¶åè¾“å‡ºå¹¶é€€å‡º ----
export const runWorkflow = async (workflow: WorkflowInput) => {
  // å¼ºçƒˆå»ºè®®åœ¨å¤–éƒ¨ï¼ˆshellï¼‰è®¾ç½® OPENAI_API_KEY
  if (!process.env.OPENAI_API_KEY) {
    throw new Error("Missing OPENAI_API_KEY");
  }

  const runner = new Runner({
    workflowName: "OpenIsle Bot",
    traceMetadata: {
      __trace_source__: "agent-builder",
      workflow_id: "wf_69003cbd47e08190928745d3c806c0b50d1a01cfae052be8",
    },
    // å¦‚éœ€å®Œå…¨ç¦ç”¨ä¸ŠæŠ¥å¯åŠ ï¼štracingDisabled: true
  });

  return await withTrace("OpenIsle Bot run", async () => {
    // Runner.run ä¼šè‡ªåŠ¨å¾ªç¯æ‰§è¡Œï¼šLLM â†’ å·¥å…· â†’ ç›´è‡³ finalOutput
    const result = await runner.run(openisleBot, workflow.input_as_text, {
      maxTurns: 16, // å…è®¸æ›´å¤æ‚ä»»åŠ¡å¤šè½®è°ƒç”¨ MCP
      // stream: true  // å¦‚éœ€è¾¹è·‘è¾¹çœ‹äº‹ä»¶å¯æ‰“å¼€ï¼Œç„¶åæ¶ˆè´¹æµäº‹ä»¶
    });

    if (!result.finalOutput) {
      // è‹¥æ²¡äº§å‡ºæœ€ç»ˆç»“æœï¼Œé€šå¸¸æ˜¯å¯ç”¨äº†äººå·¥æ‰¹å‡†/å·¥å…·å¤±è´¥/è¾¾åˆ° maxTurns
      throw new Error("Agent result is undefined (no final output).");
    }

    const openisleBotResult = { output_text: String(result.finalOutput) };

    console.log("ğŸ¤– Agent result:\n" + openisleBotResult.output_text);
    return openisleBotResult;
  });
};

// ---- CLI è¿è¡Œï¼ˆç¤ºèŒƒï¼‰----
if (require.main === module) {
  (async () => {
    try {
      const query =
        process.argv.slice(2).join(" ") || "ä½ å¥½ï¼ŒååŠ©çœ‹çœ‹æœ‰ä»€ä¹ˆæœªè¯»æ¶ˆæ¯ï¼Œå¹¶ç»“åˆå¸–å­å†…å®¹/è¯„è®ºå†…å®¹äºˆä»¥å›å¤";
      console.log("ğŸ” Running workflow...");
      await runWorkflow({ input_as_text: query });
      process.exit(0);
    } catch (err: any) {
      console.error("âŒ Agent failed:", err?.stack || err);
      process.exit(1);
    }
  })();
}
